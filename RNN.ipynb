{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##***Configuration***"
      ],
      "metadata": {
        "id": "xLVkbIK-ksS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7srCyMs7ORo9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Drive Connection***"
      ],
      "metadata": {
        "id": "xkS8Ihjfke4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "LSNagHf5Pgnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55051d89-f9fd-4ca7-edf3-6a477976e474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Load Dataset***"
      ],
      "metadata": {
        "id": "hZuSBN0sklI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the csv file from my drive\n",
        "df = pd.read_csv('/content/drive/My Drive/training.csv', encoding='latin-1')\n",
        "#defining the csv columns\n",
        "df.columns=['target','id','date','query-flag','user', 'tweet_text']\n",
        "# convert values to 0 for negative and 1 for postive\n",
        "df['target'] = np.where(df['target'] == 4,1,0)"
      ],
      "metadata": {
        "id": "mrWricBSPih_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df['target'])"
      ],
      "metadata": {
        "id": "Udy8-4YtNsot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c993be6c-f79e-4c42-a408-91c0b8a77f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          0\n",
            "1          0\n",
            "2          0\n",
            "3          0\n",
            "4          0\n",
            "          ..\n",
            "1599994    1\n",
            "1599995    1\n",
            "1599996    1\n",
            "1599997    1\n",
            "1599998    1\n",
            "Name: target, Length: 1599999, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "id": "EtlaOTJmYtfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bb19f6-03e3-4112-9cbf-e2967809a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1599999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Dataset Splitting***"
      ],
      "metadata": {
        "id": "dfdiP32q1xOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the dataset into Training [80%], Validation [10%], Testing [10%] sets.\n",
        "train_df, test_validation_df = train_test_split(df, test_size=0.2, random_state=123)\n",
        "validation_df, test_df = train_test_split(test_validation_df, test_size=0.5, random_state=123)\n",
        "\n",
        "# create datasets from the training and testing DataFrames\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    train_df['tweet_text'].values,\n",
        "    train_df['target'].values\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    test_df['tweet_text'].values,\n",
        "    test_df['target'].values\n",
        "))\n",
        "\n",
        "# apply batch and prefetch functions to the datasets\n",
        "BATCH_SIZE = 64\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VeUUr5nHAdq",
        "outputId": "6367f557-bff9-4e6f-9e24-757a08bfb1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training : \" + str(len(train_df)))\n",
        "print(\"Validation : \" +str(len(validation_df)))\n",
        "print(\"Testing : \" +str(len(test_df)))\n",
        "# 1279999, 160000, 160000"
      ],
      "metadata": {
        "id": "LLJZorDwP_tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4638be9-a757-47a6-94ec-16e80acf8403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training : 1279999\n",
            "Validation : 160000\n",
            "Testing : 160000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3wtujf8Fsps",
        "outputId": "88bf8fe7-5e7b-4988-cefc-31c2c3e59f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1559756    1\n",
            "51568      0\n",
            "569210     0\n",
            "71896      0\n",
            "405089     0\n",
            "          ..\n",
            "1241052    1\n",
            "1066306    1\n",
            "28030      0\n",
            "277869     0\n",
            "773630     0\n",
            "Name: target, Length: 1279999, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "    text =row['tweet_text']\n",
        "    label = row['target']\n",
        "\n",
        "    text_np = np.array(text)\n",
        "    label_np = np.array(label)\n",
        "    print('text: ', text_np)\n",
        "    print('label: ', label_np)"
      ],
      "metadata": {
        "id": "gI_8vJYlM201"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Preprocess***"
      ],
      "metadata": {
        "id": "qahw-ou70ccn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text and create embeddings\n",
        "max_words = 10000\n",
        "max_length = 100"
      ],
      "metadata": {
        "id": "O84sbX-7YAfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TextVectorization(max_tokens=max_words, output_mode=\"int\", output_sequence_length=max_length)\n",
        "encoder.adapt(train_df[\"tweet_text\"].values)"
      ],
      "metadata": {
        "id": "YVllBL9tX19j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = encoder.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary,range(len(vocabulary))))"
      ],
      "metadata": {
        "id": "QSjnshtkvVi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RNN**"
      ],
      "metadata": {
        "id": "qEA9qRMPLScJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "0I7lMY-u0cHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "taRkgSi92GlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae26054-66ce-4801-856e-db25b57cae77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, 100)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 100, 64)           640000    \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                3104      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 645,281\n",
            "Trainable params: 645,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wBQ_aK5jeosz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "   train_dataset, epochs=5,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30\n",
        ")"
      ],
      "metadata": {
        "id": "CLurgDxMerL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5bb792-a8e6-475f-ff4f-81f71fa1b5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 1328s 66ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4018 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 1295s 65ms/step - loss: 0.4156 - accuracy: 0.7972 - val_loss: 0.3925 - val_accuracy: 0.8026\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 1287s 64ms/step - loss: 0.4046 - accuracy: 0.8036 - val_loss: 0.3888 - val_accuracy: 0.8078\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 1290s 64ms/step - loss: 0.3943 - accuracy: 0.8096 - val_loss: 0.3884 - val_accuracy: 0.8109\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 1383s 69ms/step - loss: 0.3846 - accuracy: 0.8156 - val_loss: 0.3889 - val_accuracy: 0.8099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**LSTM**"
      ],
      "metadata": {
        "id": "MSPKXp11LiOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "1Oq3zGJCLoxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mqdjUv0hK7dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(\n",
        "   train_dataset, epochs=5,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30\n",
        ")"
      ],
      "metadata": {
        "id": "cb9Tjx_SVqX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf94171c-3a50-4b3e-a1a4-59b9e0a0042e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 2177s 109ms/step - loss: 0.4473 - accuracy: 0.7788 - val_loss: 0.4072 - val_accuracy: 0.7969\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 2188s 109ms/step - loss: 0.4164 - accuracy: 0.7971 - val_loss: 0.3921 - val_accuracy: 0.8068\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 2207s 110ms/step - loss: 0.4023 - accuracy: 0.8059 - val_loss: 0.3814 - val_accuracy: 0.8109\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 2158s 108ms/step - loss: 0.3919 - accuracy: 0.8127 - val_loss: 0.3718 - val_accuracy: 0.8151\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 2196s 110ms/step - loss: 0.3844 - accuracy: 0.8171 - val_loss: 0.3651 - val_accuracy: 0.8177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Prediction***"
      ],
      "metadata": {
        "id": "h8QvTiUvVq19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss1, test_acc1 = model.evaluate(test_dataset)\n",
        "print(\"RNN model:\")\n",
        "print('Test Loss:', test_loss1)\n",
        "print('Test Accuracy:', test_acc1)\n",
        "\n",
        "\n",
        "test_loss2, test_acc2 = model2.evaluate(test_dataset)\n",
        "print(\"LSTM model:\")\n",
        "print('Test Loss:', test_loss2)\n",
        "print('Test Accuracy:', test_acc2)\n",
        "\n"
      ],
      "metadata": {
        "id": "Kaenrufvtp11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98101092-d85a-4ed7-a53a-4fb5e248315c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 [==============================] - 42s 17ms/step - loss: 0.4156 - accuracy: 0.7964\n",
            "RNN model:\n",
            "Test Loss: 0.4155820310115814\n",
            "Test Accuracy: 0.7963937520980835\n",
            "2500/2500 [==============================] - 70s 28ms/step - loss: 0.3971 - accuracy: 0.8053\n",
            "LSTM model:\n",
            "Test Loss: 0.3971339464187622\n",
            "Test Accuracy: 0.8052999973297119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = [\n",
        "    [\"RNN Model\", test_loss1, test_acc1],\n",
        "    [\"LSTM Model\", test_loss2, test_acc2]\n",
        "]\n",
        "\n",
        "headers = [\"Model\",\"Test Loss\", \"Test Accuracy\"]\n",
        "print(tabulate(table, headers= headers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r9svsYWt5PZ",
        "outputId": "e5c11e21-6069-4502-a613-9dd6463f3d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model         Test Loss    Test Accuracy\n",
            "----------  -----------  ---------------\n",
            "RNN Model      0.415582         0.796394\n",
            "LSTM Model     0.397134         0.8053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fo9zExBVdcgv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}